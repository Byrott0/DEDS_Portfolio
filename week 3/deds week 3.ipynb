{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importeren "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "import sqlite3 as sql\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "leegmaken van tabellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Disabling constraints for CRM_RETAILER_SITE...\n",
      "  Disabling constraints for INVENTORY_LEVELS...\n",
      "  Disabling constraints for ORDER_DETAILS...\n",
      "  Disabling constraints for ORDER_HEADER...\n",
      "  Disabling constraints for PRODUCT_FORECAST...\n",
      "  Disabling constraints for RETAILER...\n",
      "  Disabling constraints for RETAILER_CONTACT...\n",
      "  Disabling constraints for RETURNED_ITEM...\n",
      "  Disabling constraints for SALES_BRANCH...\n",
      "  Disabling constraints for SALES_DEMOGRAPHIC...\n",
      "  Disabling constraints for SALES_STAFF...\n",
      "  Disabling constraints for SATISFACTION...\n",
      "  Disabling constraints for TRAINING...\n",
      "All constraints disabled\n",
      " Legen van tabel: AGE_GROUP\n",
      " Legen van tabel: COUNTRY\n",
      " Legen van tabel: COURSE\n",
      " Legen van tabel: CRM_RETAILER_SITE\n",
      " Legen van tabel: INVENTORY_LEVELS\n",
      " Legen van tabel: ORDER_DETAILS\n",
      " Legen van tabel: ORDER_HEADER\n",
      " Legen van tabel: PRODUCT\n",
      " Legen van tabel: PRODUCT_FORECAST\n",
      " Legen van tabel: RETAILER\n",
      " Legen van tabel: RETAILER_CONTACT\n",
      " Legen van tabel: RETAILER_SEGMENT\n",
      " Legen van tabel: RETURN_REASON\n",
      " Legen van tabel: RETURNED_ITEM\n",
      " Legen van tabel: SALES_BRANCH\n",
      " Legen van tabel: SALES_DEMOGRAPHIC\n",
      " Legen van tabel: SALES_STAFF\n",
      " Legen van tabel: SATISFACTION\n",
      " Legen van tabel: TRAINING\n",
      "  Re-enabling constraints for CRM_RETAILER_SITE...\n",
      "  Re-enabling constraints for INVENTORY_LEVELS...\n",
      "  Re-enabling constraints for ORDER_DETAILS...\n",
      "  Re-enabling constraints for ORDER_HEADER...\n",
      "  Re-enabling constraints for PRODUCT_FORECAST...\n",
      "  Re-enabling constraints for RETAILER...\n",
      "  Re-enabling constraints for RETAILER_CONTACT...\n",
      "  Re-enabling constraints for RETURNED_ITEM...\n",
      "  Re-enabling constraints for SALES_BRANCH...\n",
      "  Re-enabling constraints for SALES_DEMOGRAPHIC...\n",
      "  Re-enabling constraints for SALES_STAFF...\n",
      "  Re-enabling constraints for SATISFACTION...\n",
      "  Re-enabling constraints for TRAINING...\n",
      "All constraints re-enabled successfully\n",
      " Alle tabellen in de database 'sdm' zijn geleegd.\n"
     ]
    }
   ],
   "source": [
    "# Connect to the database\n",
    "conn = pyodbc.connect(\n",
    "    'DRIVER={ODBC Driver 17 for SQL Server};'\n",
    "    'SERVER=MSI\\\\SQLEXPRESS;' \n",
    "    'DATABASE=DWH;' \n",
    "    'Trusted_Connection=yes;'\n",
    ")\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Get all tables with constraints\n",
    "tables_query = \"\"\"\n",
    "SELECT DISTINCT OBJECT_NAME(parent_object_id) AS TableName\n",
    "FROM sys.foreign_keys\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    cursor.execute(tables_query)\n",
    "    tables_with_constraints = [row[0] for row in cursor.fetchall()]\n",
    "    \n",
    "    # Disable constraints for each table individually\n",
    "    for table in tables_with_constraints:\n",
    "        print(f\"  Disabling constraints for {table}...\")\n",
    "        cursor.execute(f\"ALTER TABLE [{table}] NOCHECK CONSTRAINT ALL\")\n",
    "        conn.commit()\n",
    "    \n",
    "    print(\"All constraints disabled\")\n",
    "except Exception as e:\n",
    "    print(f\"Error disabling constraints: {str(e)}\")\n",
    "\n",
    "\n",
    "# Get  tables\n",
    "cursor.execute(\"SELECT TABLE_NAME FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_TYPE = 'BASE TABLE'\")\n",
    "all_tables = [row[0] for row in cursor.fetchall()]\n",
    "\n",
    "# Empty elk table\n",
    "for table_name in all_tables:\n",
    "    print(f\" Legen van tabel: {table_name}\")\n",
    "    try:\n",
    "        cursor.execute(f\"DELETE FROM [{table_name}];\")\n",
    "        conn.commit()\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting from {table_name}: {str(e)}\")\n",
    "\n",
    "# Re-enable constraints\n",
    "try:\n",
    "    # Re-enable constraints for each table individually\n",
    "    for table in tables_with_constraints:\n",
    "        print(f\"  Re-enabling constraints for {table}...\")\n",
    "        cursor.execute(f\"ALTER TABLE [{table}] WITH CHECK CHECK CONSTRAINT ALL\")\n",
    "        conn.commit()\n",
    "    \n",
    "    print(\"All constraints re-enabled successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error re-enabling constraints: {str(e)}\")\n",
    "\n",
    "print(\" Alle tabellen in de database 'sdm' zijn geleegd.\")\n",
    "\n",
    "# Close connections at the very end\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deds data omzetten van sqlite en csv naar datawarehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to SQL Server database\n",
      "Found 19 tables in SQL Server database\n",
      "Disabling constraints...\n",
      "Processing SQLite database: go_sales_train.sqlite\n",
      "Importing table: product\n",
      "Successfully imported table: product\n",
      "Importing table: order_details\n",
      "Successfully imported table: order_details\n",
      "Importing table: sales_branch\n",
      "Successfully imported table: sales_branch\n",
      "Importing table: returned_item\n",
      "Successfully imported table: returned_item\n",
      "Importing table: sales_staff\n",
      "Successfully imported table: sales_staff\n",
      "Processing SQLite database: go_staff_train.sqlite\n",
      "Importing table: training\n",
      "Successfully imported table: training\n",
      "Importing table: course\n",
      "Successfully imported table: course\n",
      "Importing table: satisfaction\n",
      "Starting SATISFACTION_CODE counter at 1\n",
      "Successfully imported table: satisfaction\n",
      "Importing table: satisfaction_type\n",
      "Table satisfaction_type not found in SQL Server, skipping...\n",
      "Processing SQLite database: go_crm_train.sqlite\n",
      "Importing table: country\n",
      "Successfully imported table: country\n",
      "Importing product_forecast_train.csv to PRODUCT_FORECAST\n",
      "Successfully imported product_forecast_train.csv\n",
      "Importing inventory_levels_train.csv to INVENTORY_LEVELS\n",
      "Successfully imported inventory_levels_train.csv\n",
      "Re-enabling constraints...\n",
      "Database import completed successfully\n",
      "Import completed successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# function naar python types\n",
    "def convert_numpy_type(val):\n",
    "    if pd.isnull(val):\n",
    "        return None\n",
    "    elif hasattr(val, 'item'):  # Handles numpy types (int64, float64, etc.)\n",
    "        return val.item()\n",
    "    else:\n",
    "        return val\n",
    "\n",
    "# Helper function to handle type conversions\n",
    "def convert_value_for_column(value, column_name, column_type, table_name):\n",
    "    \"\"\"Converts a value to the appropriate type for the target column.\"\"\"\n",
    "    if value is None:\n",
    "        # Handle NOT NULL constraints by providing default values\n",
    "        if table_name == 'TRAINING' and column_name == 'TRAINING_CODE':\n",
    "            return 0  # Default value for TRAINING_CODE\n",
    "        elif table_name == 'SATISFACTION' and column_name == 'SATISFACTION_CODE':\n",
    "            return 0  # Default value for SATISFACTION_CODE\n",
    "        return None\n",
    "    \n",
    "    # Convert based on target column type\n",
    "    try:\n",
    "        if 'INT' in column_type.upper():\n",
    "            # For INT columns\n",
    "            if isinstance(value, str):\n",
    "                # Try to convert string to int\n",
    "                try:\n",
    "                    return int(value)\n",
    "                except ValueError:\n",
    "                    print(f\"Cannot convert '{value}' to INT for {table_name}.{column_name}, using default\")\n",
    "                    return 0\n",
    "            return int(value) if value is not None else None\n",
    "        \n",
    "        elif 'REAL' in column_type.upper() or 'FLOAT' in column_type.upper() or 'DECIMAL' in column_type.upper():\n",
    "            # For floating-point columns\n",
    "            if isinstance(value, str):\n",
    "                try:\n",
    "                    return float(value)\n",
    "                except ValueError:\n",
    "                    print(f\"Cannot convert '{value}' to REAL for {table_name}.{column_name}, using default\")\n",
    "                    return 0.0\n",
    "            return float(value) if value is not None else None\n",
    "        \n",
    "        elif 'TEXT' in column_type.upper() or 'VARCHAR' in column_type.upper() or 'CHAR' in column_type.upper():\n",
    "            # For text columns\n",
    "            return str(value) if value is not None else None\n",
    "        \n",
    "        elif 'DATE' in column_type.upper():\n",
    "            # For date columns\n",
    "            return value\n",
    "        \n",
    "        elif 'BIT' in column_type.upper():\n",
    "            # For boolean columns\n",
    "            if isinstance(value, bool):\n",
    "                return 1 if value else 0\n",
    "            elif isinstance(value, (int, float)):\n",
    "                return 1 if value > 0 else 0\n",
    "            elif isinstance(value, str):\n",
    "                return 1 if value.lower() in ('true', 'yes', 'y', '1') else 0\n",
    "            return 0\n",
    "            \n",
    "        else:\n",
    "            # Default handling for other types\n",
    "            return value\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting value '{value}' for {table_name}.{column_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to get column types from a table\n",
    "def get_column_types(cursor, table_name):\n",
    "    \"\"\"Gets the data types of columns in a table.\"\"\"\n",
    "    column_types = {}\n",
    "    cursor.execute(f\"SELECT COLUMN_NAME, DATA_TYPE FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '{table_name}'\")\n",
    "    for row in cursor.fetchall():\n",
    "        column_types[row[0]] = row[1]\n",
    "    return column_types\n",
    "\n",
    "# Function to check if a column has a NOT NULL constraint\n",
    "def get_nullable_columns(cursor, table_name):\n",
    "    \"\"\"Gets information about which columns are nullable.\"\"\"\n",
    "    nullable_info = {}\n",
    "    cursor.execute(f\"SELECT COLUMN_NAME, IS_NULLABLE FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '{table_name}'\")\n",
    "    for row in cursor.fetchall():\n",
    "        nullable_info[row[0]] = row[1] == 'YES'\n",
    "    return nullable_info\n",
    "\n",
    "# Main function to import data\n",
    "def import_data():\n",
    "    try:\n",
    "        # Connect to SQL Server\n",
    "        conn = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server};SERVER=MSI\\\\SQLEXPRESS;DATABASE=DWH;Trusted_Connection=yes;')\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        print(\"Connected to SQL Server database\")\n",
    "        \n",
    "        # Get list of tables in SQL Server\n",
    "        cursor.execute(\"SELECT TABLE_NAME FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_TYPE = 'BASE TABLE'\")\n",
    "        sql_tables = [row[0] for row in cursor.fetchall()]\n",
    "        print(f\"Found {len(sql_tables)} tables in SQL Server database\")\n",
    "        \n",
    "        # Disable constraints\n",
    "        print(\"Disabling constraints...\")\n",
    "        cursor.execute(\"SELECT DISTINCT OBJECT_NAME(parent_object_id) FROM sys.foreign_keys\")\n",
    "        tables = [row[0] for row in cursor.fetchall()]\n",
    "        for table in tables:\n",
    "            cursor.execute(f\"ALTER TABLE [{table}] NOCHECK CONSTRAINT ALL\")\n",
    "        conn.commit()\n",
    "        \n",
    "        # SQLite imports\n",
    "        sqlite_files = [\n",
    "            {\"db\": \"go_sales_train.sqlite\", \"tables\": [\"product\", \"order_details\", \"sales_branch\", \"returned_item\", \"sales_staff\"]},\n",
    "            {\"db\": \"go_staff_train.sqlite\", \"tables\": [\"training\", \"course\", \"satisfaction\", \"satisfaction_type\"]},\n",
    "            {\"db\": \"go_crm_train.sqlite\", \"tables\": [\"country\"]}\n",
    "        ]\n",
    "        \n",
    "        for file in sqlite_files:\n",
    "            db_path = f\"{file['db']}\"\n",
    "            print(f\"Processing SQLite database: {file['db']}\")\n",
    "            \n",
    "            try:\n",
    "                conn_sqlite = sql.connect(db_path)\n",
    "                for table in file[\"tables\"]:\n",
    "                    print(f\"Importing table: {table}\")\n",
    "                    \n",
    "                    # Check if table exists in SQL Server\n",
    "                    if table.upper() not in [t.upper() for t in sql_tables]:\n",
    "                        print(f\"Table {table} not found in SQL Server, skipping...\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Get column information\n",
    "                    column_types = get_column_types(cursor, table)\n",
    "                    nullable_info = get_nullable_columns(cursor, table)\n",
    "                    \n",
    "                    # Read data from SQLite\n",
    "                    df = pd.read_sql(f\"SELECT * FROM {table}\", conn_sqlite)\n",
    "                    if df.empty:\n",
    "                        print(f\"No data found in {table}, skipping...\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Get SQL Server columns\n",
    "                    cursor.execute(f\"SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '{table}'\")\n",
    "                    sql_cols = [row[0] for row in cursor.fetchall()]\n",
    "                    \n",
    "                    # Find common columns\n",
    "                    common_cols = []\n",
    "                    for col in df.columns:\n",
    "                        matching_cols = [s_col for s_col in sql_cols if s_col.upper() == col.upper()]\n",
    "                        if matching_cols:\n",
    "                            common_cols.append((col, matching_cols[0]))  # (sqlite_col, sql_server_col)\n",
    "                    \n",
    "                    if not common_cols:\n",
    "                        print(f\"No matching columns found for {table}, skipping...\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Prepare SQL statement\n",
    "                    sql_cols_str = \", \".join([f\"[{col[1]}]\" for col in common_cols])\n",
    "                    placeholders = \", \".join([\"?\"] * len(common_cols))\n",
    "                    \n",
    "                    # Special handling for SATISFACTION table\n",
    "                    if table.upper() == 'SATISFACTION':\n",
    "                        # Initialize satisfaction_code_counter\n",
    "                        try:\n",
    "                            cursor.execute(\"SELECT MAX(SATISFACTION_CODE) FROM SATISFACTION\")\n",
    "                            max_code = cursor.fetchone()[0]\n",
    "                            satisfaction_code_counter = (max_code or 0) + 1\n",
    "                        except:\n",
    "                            satisfaction_code_counter = 1\n",
    "                            \n",
    "                        print(f\"Starting SATISFACTION_CODE counter at {satisfaction_code_counter}\")\n",
    "                        \n",
    "                        # Insert data with generated SATISFACTION_CODE\n",
    "                        for _, row in df.iterrows():\n",
    "                            try:\n",
    "                                # Add SATISFACTION_CODE to column list and values\n",
    "                                updated_cols = \"SATISFACTION_CODE, \" + sql_cols_str\n",
    "                                updated_placeholders = \"?, \" + placeholders\n",
    "                                \n",
    "                                # Convert values starting with the SATISFACTION_CODE\n",
    "                                values = [satisfaction_code_counter]\n",
    "                                \n",
    "                                for sqlite_col, sql_col in common_cols:\n",
    "                                    value = convert_numpy_type(row[sqlite_col])\n",
    "                                    col_type = column_types.get(sql_col, 'TEXT')\n",
    "                                    converted_value = convert_value_for_column(value, sql_col, col_type, table.upper())\n",
    "                                    values.append(converted_value)\n",
    "                                \n",
    "                                # Execute insert\n",
    "                                cursor.execute(f\"INSERT INTO {table} ({updated_cols}) VALUES ({updated_placeholders})\", tuple(values))\n",
    "                                \n",
    "                                # Increment counter\n",
    "                                satisfaction_code_counter += 1\n",
    "                            except Exception as e:\n",
    "                                print(f\"Error inserting row in {table}: {e}\")\n",
    "                    else:\n",
    "                        # Standard insert for other tables\n",
    "                        for _, row in df.iterrows():\n",
    "                            try:\n",
    "                                # Convert values\n",
    "                                values = []\n",
    "                                for sqlite_col, sql_col in common_cols:\n",
    "                                    value = convert_numpy_type(row[sqlite_col])\n",
    "                                    col_type = column_types.get(sql_col, 'TEXT')\n",
    "                                    converted_value = convert_value_for_column(value, sql_col, col_type, table.upper())\n",
    "                                    values.append(converted_value)\n",
    "                                \n",
    "                                # Execute insert\n",
    "                                cursor.execute(f\"INSERT INTO {table} ({sql_cols_str}) VALUES ({placeholders})\", tuple(values))\n",
    "                            except Exception as e:\n",
    "                                print(f\"Error inserting row in {table}: {e}\")\n",
    "                    \n",
    "                    # Commit after each table\n",
    "                    conn.commit()\n",
    "                    print(f\"Successfully imported table: {table}\")\n",
    "                \n",
    "                conn_sqlite.close()\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing SQLite database {file['db']}: {e}\")\n",
    "        \n",
    "        # CSV imports with specific column handling\n",
    "        csv_files = {\n",
    "            \"product_forecast_train.csv\": {\n",
    "                \"table\": \"PRODUCT_FORECAST\",\n",
    "                \"mapping\": {\n",
    "                    \"`PRODUCT_NUMBER\": \"PRODUCT_NUMBER\",\n",
    "                    \"YEAR\": \"YEAR\",\n",
    "                    \"MONTH\": \"MONTH\",\n",
    "                    \"EXPECTED_VOLUME\": \"EXPECTED_VOLUME\"\n",
    "                }\n",
    "            },\n",
    "            \"inventory_levels_train.csv\": {\n",
    "                \"table\": \"INVENTORY_LEVELS\",\n",
    "                \"mapping\": {\n",
    "                    \"Unnamed: 0\": \"ID\",\n",
    "                    \"INVENTORY_YEAR\": \"INVENTORY_YEAR\",\n",
    "                    \"INVENTORY_MONTH\": \"INVENTORY_MONTH\",\n",
    "                    \"PRODUCT_NUMBER\": \"PRODUCT_NUMBER\",\n",
    "                    \"INVENTORY_COUNT\": \"INVENTORY_COUNT\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        for csv_file, info in csv_files.items():\n",
    "            table_name = info[\"table\"]\n",
    "            column_mapping = info[\"mapping\"]\n",
    "            \n",
    "            print(f\"Importing {csv_file} to {table_name}\")\n",
    "            \n",
    "            try:\n",
    "                # Get column information\n",
    "                column_types = get_column_types(cursor, table_name)\n",
    "                nullable_info = get_nullable_columns(cursor, table_name)\n",
    "                \n",
    "                # Read CSV file\n",
    "                csv_path = f\"{csv_file}\"\n",
    "                df = pd.read_csv(csv_path)\n",
    "                \n",
    "                # Rename columns according to mapping\n",
    "                rename_dict = {}\n",
    "                for csv_col, sql_col in column_mapping.items():\n",
    "                    if csv_col in df.columns:\n",
    "                        rename_dict[csv_col] = sql_col\n",
    "                \n",
    "                if rename_dict:\n",
    "                    df = df.rename(columns=rename_dict)\n",
    "                \n",
    "                # Get SQL Server columns\n",
    "                cursor.execute(f\"SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '{table_name}'\")\n",
    "                sql_cols = [row[0] for row in cursor.fetchall()]\n",
    "                \n",
    "                # Find common columns\n",
    "                common_cols = [col for col in df.columns if col in sql_cols]\n",
    "                \n",
    "                if not common_cols:\n",
    "                    print(f\"No matching columns found for {table_name}, skipping...\")\n",
    "                    continue\n",
    "                \n",
    "                # Prepare SQL statement\n",
    "                cols_str = \", \".join([f\"[{col}]\" for col in common_cols])\n",
    "                placeholders = \", \".join([\"?\"] * len(common_cols))\n",
    "                \n",
    "                # Insert data\n",
    "                for _, row in df.iterrows():\n",
    "                    try:\n",
    "                        # Convert values\n",
    "                        values = []\n",
    "                        for col in common_cols:\n",
    "                            value = convert_numpy_type(row[col])\n",
    "                            col_type = column_types.get(col, 'TEXT')\n",
    "                            converted_value = convert_value_for_column(value, col, col_type, table_name)\n",
    "                            values.append(converted_value)\n",
    "                        \n",
    "                        # Execute insert\n",
    "                        cursor.execute(f\"INSERT INTO {table_name} ({cols_str}) VALUES ({placeholders})\", tuple(values))\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error inserting row in {table_name}: {e}\")\n",
    "                \n",
    "                # Commit after each file\n",
    "                conn.commit()\n",
    "                print(f\"Successfully imported {csv_file}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error importing CSV file {csv_file}: {e}\")\n",
    "        \n",
    "        # Re-enable constraints with NOCHECK\n",
    "        print(\"Re-enabling constraints...\")\n",
    "        for table in tables:\n",
    "            cursor.execute(f\"ALTER TABLE [{table}] WITH NOCHECK CHECK CONSTRAINT ALL\")\n",
    "        conn.commit()\n",
    "        \n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        print(\"Database import completed successfully\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Fatal error during import: {e}\")\n",
    "        raise\n",
    "\n",
    "# Execute the import function\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        import_data()\n",
    "        print(\"Import completed successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Import failed: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
